{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trajectory(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.trajectory = []\n",
    "        self.total_return = 0\n",
    "        self.length = 0\n",
    "        \n",
    "    def add(self, state, action, reward, state_prime):\n",
    "        self.trajectory.append((state, action, reward, state_prime))\n",
    "        self.total_return += reward\n",
    "        self.length += 1\n",
    "        \n",
    "    def sample_segment(self):\n",
    "        T = len(self.trajectory)\n",
    "\n",
    "        t1 = np.random.randint(1, T+1)\n",
    "        t2 = np.random.randint(t1, T+1)\n",
    "\n",
    "        state = self.trajectory[t1-1][0]\n",
    "        action = self.trajectory[t1-1][1]\n",
    "\n",
    "        d_r = 0.0\n",
    "        for i in range(t1, t2 + 1):\n",
    "            d_r += self.trajectory[i-1][2]\n",
    "\n",
    "        d_h = t2 - t1 + 1.0\n",
    "\n",
    "        return ((state,d_r,d_h),action)\n",
    "    \n",
    "class ReplayBuffer(object):\n",
    "    \n",
    "    def __init__(self, max_size, last_few):\n",
    "        \"\"\"\n",
    "        @param last_few: Number of episodes from the end of the replay buffer\n",
    "        used for sampling exploratory commands.\n",
    "        \"\"\"\n",
    "        self.max_size = max_size\n",
    "        self.cur_size = 0\n",
    "        self.buffer = []\n",
    "        \n",
    "        self.last_few = last_few\n",
    "        \n",
    "    def add(self, trajectory):\n",
    "        self.buffer.append(trajectory)\n",
    "        \n",
    "        self.buffer = sorted(self.buffer, key=lambda x: x.total_return, reverse=True)\n",
    "        self.buffer = self.buffer[:self.max_size]\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        trajectories = np.random.choice(self.buffer, batch_size, replace=True)\n",
    "        \n",
    "        segments = []\n",
    "        \n",
    "        for t in trajectories:\n",
    "            segments.append(t.sample_segment())\n",
    "            \n",
    "        return segments\n",
    "    \n",
    "    def sample_command(self):\n",
    "        eps = self.buffer[:self.last_few]\n",
    "        \n",
    "        dh_0 = np.mean([e.length for e in eps])\n",
    "        \n",
    "        m = np.mean([e.total_return for e in eps])\n",
    "        s = np.std([e.total_return for e in eps])\n",
    "        \n",
    "        dr_0 = np.random.uniform(m, m+s)\n",
    "        \n",
    "        return dh_0, dr_0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1-1. Initialize replay buffer with warm-up episodes using random actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Episode Reward: 22.2368\n"
     ]
    }
   ],
   "source": [
    "rb = ReplayBuffer(5000, 100)\n",
    "\n",
    "avg_rewards = []\n",
    "\n",
    "for _ in range(5000):\n",
    "    s = env.reset()\n",
    "    done = False\n",
    "    ep_reward = 0.0\n",
    "    t = Trajectory()\n",
    "    while not done:\n",
    "        # env.render()\n",
    "        s_old = s\n",
    "        action = env.action_space.sample()\n",
    "        s, reward, done, info = env.step(action)\n",
    "        t.add(s_old, action, reward, s)\n",
    "        ep_reward += reward\n",
    "    avg_rewards.append(ep_reward)    \n",
    "    # print(f'Episode reward: {ep_reward}')\n",
    "    rb.add(t)\n",
    "    \n",
    "    \n",
    "env.close()\n",
    "print(f\"Average Episode Reward: {np.mean(avg_rewards)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1-2 Initialize a behavior function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Behavior(nn.Module):\n",
    "    def __init__(self, input_shape, num_actions):\n",
    "        super(Behavior, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape,512)\n",
    "        self.fc2 = nn.Linear(512,512)\n",
    "        self.fc3 = nn.Linear(512,num_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = F.relu(self.fc1(x))\n",
    "        output = F.relu(self.fc2(output))\n",
    "        output = self.fc3(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "d = env.observation_space.shape[0]\n",
    "model = Behavior(input_shape=d+2, num_actions=1).to(device) # env.action_space.n\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "loss_object = torch.nn.BCEWithLogitsLoss().to(device) #CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "### A1-3: while stopping criteria is not reached do:\n",
    "### A1-4:   Improve the behavior function by training on replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_sum = 0\n",
    "loss_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 20, Loss: 0.6575998663902283\n",
      "i: 40, Loss: 0.6575884819030762\n",
      "i: 60, Loss: 0.6575772166252136\n",
      "i: 80, Loss: 0.6575629711151123\n",
      "i: 100, Loss: 0.6575509905815125\n",
      "i: 120, Loss: 0.6575313210487366\n",
      "i: 140, Loss: 0.6575155258178711\n",
      "i: 160, Loss: 0.6575053334236145\n",
      "i: 180, Loss: 0.6574890613555908\n",
      "i: 200, Loss: 0.6574710607528687\n",
      "i: 220, Loss: 0.6574550867080688\n",
      "i: 240, Loss: 0.6574425101280212\n",
      "i: 260, Loss: 0.6574320197105408\n",
      "i: 280, Loss: 0.6574203372001648\n",
      "i: 300, Loss: 0.6574078798294067\n",
      "i: 320, Loss: 0.6573948860168457\n",
      "i: 340, Loss: 0.6573821902275085\n",
      "i: 360, Loss: 0.6573679447174072\n",
      "i: 380, Loss: 0.657350480556488\n",
      "i: 400, Loss: 0.6573327779769897\n",
      "i: 420, Loss: 0.657323956489563\n",
      "i: 440, Loss: 0.6573086380958557\n",
      "i: 460, Loss: 0.6572924852371216\n",
      "i: 480, Loss: 0.6572871804237366\n",
      "i: 500, Loss: 0.6572737693786621\n",
      "i: 520, Loss: 0.6572664380073547\n",
      "i: 540, Loss: 0.6572550535202026\n",
      "i: 560, Loss: 0.6572429537773132\n",
      "i: 580, Loss: 0.6572306156158447\n",
      "i: 600, Loss: 0.6572176218032837\n",
      "i: 620, Loss: 0.6572049260139465\n",
      "i: 640, Loss: 0.6571989059448242\n",
      "i: 660, Loss: 0.6571875810623169\n",
      "i: 680, Loss: 0.657171905040741\n",
      "i: 700, Loss: 0.6571584939956665\n",
      "i: 720, Loss: 0.6571438312530518\n",
      "i: 740, Loss: 0.6571307182312012\n",
      "i: 760, Loss: 0.6571149826049805\n",
      "i: 780, Loss: 0.6571019291877747\n",
      "i: 800, Loss: 0.6570861339569092\n",
      "i: 820, Loss: 0.6570695042610168\n",
      "i: 840, Loss: 0.6570596694946289\n",
      "i: 860, Loss: 0.6570420861244202\n",
      "i: 880, Loss: 0.6570309400558472\n",
      "i: 900, Loss: 0.657021701335907\n",
      "i: 920, Loss: 0.6570133566856384\n",
      "i: 940, Loss: 0.6570013165473938\n",
      "i: 960, Loss: 0.656989336013794\n",
      "i: 980, Loss: 0.6569775342941284\n",
      "i: 1000, Loss: 0.65696781873703\n",
      "i: 1020, Loss: 0.656956136226654\n",
      "i: 1040, Loss: 0.6569458246231079\n",
      "i: 1060, Loss: 0.6569328904151917\n",
      "i: 1080, Loss: 0.6569246053695679\n",
      "i: 1100, Loss: 0.6569141745567322\n",
      "i: 1120, Loss: 0.6568998694419861\n",
      "i: 1140, Loss: 0.6568834781646729\n",
      "i: 1160, Loss: 0.6568722128868103\n",
      "i: 1180, Loss: 0.6568641066551208\n",
      "i: 1200, Loss: 0.6568464636802673\n",
      "i: 1220, Loss: 0.6568315625190735\n",
      "i: 1240, Loss: 0.656815230846405\n",
      "i: 1260, Loss: 0.6568006873130798\n",
      "i: 1280, Loss: 0.6567924618721008\n",
      "i: 1300, Loss: 0.6567813158035278\n",
      "i: 1320, Loss: 0.6567687392234802\n",
      "i: 1340, Loss: 0.6567544341087341\n",
      "i: 1360, Loss: 0.6567443013191223\n",
      "i: 1380, Loss: 0.6567374467849731\n",
      "i: 1400, Loss: 0.6567249298095703\n",
      "i: 1420, Loss: 0.6567135453224182\n",
      "i: 1440, Loss: 0.656702995300293\n",
      "i: 1460, Loss: 0.6566910743713379\n",
      "i: 1480, Loss: 0.6566807627677917\n",
      "i: 1500, Loss: 0.6566678285598755\n",
      "i: 1520, Loss: 0.6566553711891174\n",
      "i: 1540, Loss: 0.6566417217254639\n",
      "i: 1560, Loss: 0.6566271185874939\n",
      "i: 1580, Loss: 0.6566193103790283\n",
      "i: 1600, Loss: 0.6566091179847717\n",
      "i: 1620, Loss: 0.6565996408462524\n",
      "i: 1640, Loss: 0.6565895676612854\n",
      "i: 1660, Loss: 0.6565732955932617\n",
      "i: 1680, Loss: 0.6565653681755066\n",
      "i: 1700, Loss: 0.6565531492233276\n",
      "i: 1720, Loss: 0.6565394401550293\n",
      "i: 1740, Loss: 0.6565271019935608\n",
      "i: 1760, Loss: 0.6565160155296326\n",
      "i: 1780, Loss: 0.6565043330192566\n",
      "i: 1800, Loss: 0.6564930081367493\n",
      "i: 1820, Loss: 0.6564827561378479\n",
      "i: 1840, Loss: 0.6564706563949585\n",
      "i: 1860, Loss: 0.6564634442329407\n",
      "i: 1880, Loss: 0.6564491391181946\n",
      "i: 1900, Loss: 0.6564355492591858\n",
      "i: 1920, Loss: 0.6564264297485352\n",
      "i: 1940, Loss: 0.6564154624938965\n",
      "i: 1960, Loss: 0.656405508518219\n",
      "i: 1980, Loss: 0.6563984155654907\n",
      "i: 2000, Loss: 0.656387448310852\n",
      "i: 2020, Loss: 0.6563782691955566\n",
      "i: 2040, Loss: 0.656364917755127\n",
      "i: 2060, Loss: 0.656352162361145\n",
      "i: 2080, Loss: 0.6563405990600586\n",
      "i: 2100, Loss: 0.6563292741775513\n",
      "i: 2120, Loss: 0.656314492225647\n",
      "i: 2140, Loss: 0.656302809715271\n",
      "i: 2160, Loss: 0.656288743019104\n",
      "i: 2180, Loss: 0.6562816500663757\n",
      "i: 2200, Loss: 0.6562663912773132\n",
      "i: 2220, Loss: 0.6562532186508179\n",
      "i: 2240, Loss: 0.6562378406524658\n",
      "i: 2260, Loss: 0.6562267541885376\n",
      "i: 2280, Loss: 0.6562212705612183\n",
      "i: 2300, Loss: 0.6562080383300781\n",
      "i: 2320, Loss: 0.6562010049819946\n",
      "i: 2340, Loss: 0.6561893224716187\n",
      "i: 2360, Loss: 0.656179666519165\n",
      "i: 2380, Loss: 0.6561678647994995\n",
      "i: 2400, Loss: 0.6561570167541504\n",
      "i: 2420, Loss: 0.6561494469642639\n",
      "i: 2440, Loss: 0.6561417579650879\n",
      "i: 2460, Loss: 0.6561314463615417\n",
      "i: 2480, Loss: 0.6561220288276672\n",
      "i: 2500, Loss: 0.6561117768287659\n",
      "i: 2520, Loss: 0.6561022400856018\n",
      "i: 2540, Loss: 0.6560916900634766\n",
      "i: 2560, Loss: 0.6560786366462708\n",
      "i: 2580, Loss: 0.6560658812522888\n",
      "i: 2600, Loss: 0.6560571193695068\n",
      "i: 2620, Loss: 0.6560478806495667\n",
      "i: 2640, Loss: 0.6560405492782593\n",
      "i: 2660, Loss: 0.6560319066047668\n",
      "i: 2680, Loss: 0.6560196876525879\n",
      "i: 2700, Loss: 0.6560125350952148\n",
      "i: 2720, Loss: 0.6560037732124329\n",
      "i: 2740, Loss: 0.6559914350509644\n",
      "i: 2760, Loss: 0.6559828519821167\n",
      "i: 2780, Loss: 0.6559721827507019\n",
      "i: 2800, Loss: 0.6559646725654602\n",
      "i: 2820, Loss: 0.655954897403717\n",
      "i: 2840, Loss: 0.6559464931488037\n",
      "i: 2860, Loss: 0.6559377312660217\n",
      "i: 2880, Loss: 0.6559276580810547\n",
      "i: 2900, Loss: 0.6559174656867981\n",
      "i: 2920, Loss: 0.6559060215950012\n",
      "i: 2940, Loss: 0.6558995246887207\n",
      "i: 2960, Loss: 0.6558860540390015\n",
      "i: 2980, Loss: 0.6558782458305359\n",
      "i: 3000, Loss: 0.6558677554130554\n",
      "i: 3020, Loss: 0.6558594107627869\n",
      "i: 3040, Loss: 0.6558504104614258\n",
      "i: 3060, Loss: 0.6558387279510498\n",
      "i: 3080, Loss: 0.655828058719635\n",
      "i: 3100, Loss: 0.6558184623718262\n",
      "i: 3120, Loss: 0.6558113098144531\n",
      "i: 3140, Loss: 0.6558038592338562\n",
      "i: 3160, Loss: 0.6557968258857727\n",
      "i: 3180, Loss: 0.655789852142334\n",
      "i: 3200, Loss: 0.6557808518409729\n",
      "i: 3220, Loss: 0.6557716727256775\n",
      "i: 3240, Loss: 0.6557618975639343\n",
      "i: 3260, Loss: 0.6557539701461792\n",
      "i: 3280, Loss: 0.655746579170227\n",
      "i: 3300, Loss: 0.6557347178459167\n",
      "i: 3320, Loss: 0.6557222604751587\n",
      "i: 3340, Loss: 0.6557116508483887\n",
      "i: 3360, Loss: 0.6557022333145142\n",
      "i: 3380, Loss: 0.6556926369667053\n",
      "i: 3400, Loss: 0.6556860208511353\n",
      "i: 3420, Loss: 0.6556751728057861\n",
      "i: 3440, Loss: 0.6556665897369385\n",
      "i: 3460, Loss: 0.655658483505249\n",
      "i: 3480, Loss: 0.655647337436676\n",
      "i: 3500, Loss: 0.6556389331817627\n",
      "i: 3520, Loss: 0.6556277275085449\n",
      "i: 3540, Loss: 0.6556202173233032\n",
      "i: 3560, Loss: 0.6556034088134766\n",
      "i: 3580, Loss: 0.6555906534194946\n",
      "i: 3600, Loss: 0.6555829048156738\n",
      "i: 3620, Loss: 0.65557461977005\n",
      "i: 3640, Loss: 0.6555625796318054\n",
      "i: 3660, Loss: 0.6555497646331787\n",
      "i: 3680, Loss: 0.655540943145752\n",
      "i: 3700, Loss: 0.6555333137512207\n",
      "i: 3720, Loss: 0.6555238366127014\n",
      "i: 3740, Loss: 0.6555179953575134\n",
      "i: 3760, Loss: 0.6555099487304688\n",
      "i: 3780, Loss: 0.6555014252662659\n",
      "i: 3800, Loss: 0.6554944515228271\n",
      "i: 3820, Loss: 0.6554847359657288\n",
      "i: 3840, Loss: 0.6554797291755676\n",
      "i: 3860, Loss: 0.6554695963859558\n",
      "i: 3880, Loss: 0.6554547548294067\n",
      "i: 3900, Loss: 0.6554434299468994\n",
      "i: 3920, Loss: 0.6554339528083801\n",
      "i: 3940, Loss: 0.6554218530654907\n",
      "i: 3960, Loss: 0.6554128527641296\n",
      "i: 3980, Loss: 0.6554000377655029\n",
      "i: 4000, Loss: 0.6553887724876404\n",
      "i: 4020, Loss: 0.6553834676742554\n",
      "i: 4040, Loss: 0.655373215675354\n",
      "i: 4060, Loss: 0.6553626656532288\n",
      "i: 4080, Loss: 0.655351459980011\n",
      "i: 4100, Loss: 0.6553439497947693\n",
      "i: 4120, Loss: 0.6553362011909485\n",
      "i: 4140, Loss: 0.6553266644477844\n",
      "i: 4160, Loss: 0.6553143858909607\n",
      "i: 4180, Loss: 0.655307412147522\n",
      "i: 4200, Loss: 0.6552988886833191\n",
      "i: 4220, Loss: 0.6552931666374207\n",
      "i: 4240, Loss: 0.6552855372428894\n",
      "i: 4260, Loss: 0.6552744507789612\n",
      "i: 4280, Loss: 0.6552639007568359\n",
      "i: 4300, Loss: 0.6552555561065674\n",
      "i: 4320, Loss: 0.6552455425262451\n",
      "i: 4340, Loss: 0.6552401185035706\n",
      "i: 4360, Loss: 0.6552317142486572\n",
      "i: 4380, Loss: 0.6552255153656006\n",
      "i: 4400, Loss: 0.655214250087738\n",
      "i: 4420, Loss: 0.6552029252052307\n",
      "i: 4440, Loss: 0.6551946401596069\n",
      "i: 4460, Loss: 0.6551855802536011\n",
      "i: 4480, Loss: 0.6551822423934937\n",
      "i: 4500, Loss: 0.655174195766449\n",
      "i: 4520, Loss: 0.6551675200462341\n",
      "i: 4540, Loss: 0.6551592946052551\n",
      "i: 4560, Loss: 0.6551552414894104\n",
      "i: 4580, Loss: 0.6551451086997986\n",
      "i: 4600, Loss: 0.6551418900489807\n",
      "i: 4620, Loss: 0.6551337838172913\n",
      "i: 4640, Loss: 0.6551212668418884\n",
      "i: 4660, Loss: 0.6551132798194885\n",
      "i: 4680, Loss: 0.655106246471405\n",
      "i: 4700, Loss: 0.6550983786582947\n",
      "i: 4720, Loss: 0.6550965309143066\n",
      "i: 4740, Loss: 0.6550858020782471\n",
      "i: 4760, Loss: 0.6550769805908203\n",
      "i: 4780, Loss: 0.655066192150116\n",
      "i: 4800, Loss: 0.6550601124763489\n",
      "i: 4820, Loss: 0.6550513505935669\n",
      "i: 4840, Loss: 0.6550433039665222\n",
      "i: 4860, Loss: 0.6550342440605164\n",
      "i: 4880, Loss: 0.6550227999687195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 4900, Loss: 0.6550154089927673\n",
      "i: 4920, Loss: 0.6550066471099854\n",
      "i: 4940, Loss: 0.655002236366272\n",
      "i: 4960, Loss: 0.6549966335296631\n",
      "i: 4980, Loss: 0.654992401599884\n",
      "i: 5000, Loss: 0.6549856662750244\n",
      "i: 5020, Loss: 0.6549742221832275\n",
      "i: 5040, Loss: 0.6549717783927917\n",
      "i: 5060, Loss: 0.6549655199050903\n",
      "i: 5080, Loss: 0.6549561023712158\n",
      "i: 5100, Loss: 0.6549476385116577\n",
      "i: 5120, Loss: 0.6549401879310608\n",
      "i: 5140, Loss: 0.6549288630485535\n",
      "i: 5160, Loss: 0.6549204587936401\n",
      "i: 5180, Loss: 0.6549116969108582\n",
      "i: 5200, Loss: 0.6549047231674194\n",
      "i: 5220, Loss: 0.6548959016799927\n",
      "i: 5240, Loss: 0.6548879742622375\n",
      "i: 5260, Loss: 0.6548815369606018\n",
      "i: 5280, Loss: 0.6548735499382019\n",
      "i: 5300, Loss: 0.6548663973808289\n",
      "i: 5320, Loss: 0.6548570394515991\n",
      "i: 5340, Loss: 0.654848039150238\n",
      "i: 5360, Loss: 0.6548413634300232\n",
      "i: 5380, Loss: 0.6548348069190979\n",
      "i: 5400, Loss: 0.6548274755477905\n",
      "i: 5420, Loss: 0.6548191905021667\n",
      "i: 5440, Loss: 0.6548115015029907\n",
      "i: 5460, Loss: 0.6548041105270386\n",
      "i: 5480, Loss: 0.6547945141792297\n",
      "i: 5500, Loss: 0.6547905206680298\n",
      "i: 5520, Loss: 0.6547813415527344\n",
      "i: 5540, Loss: 0.6547720432281494\n",
      "i: 5560, Loss: 0.65476393699646\n",
      "i: 5580, Loss: 0.6547559499740601\n",
      "i: 5600, Loss: 0.6547508239746094\n",
      "i: 5620, Loss: 0.6547414660453796\n",
      "i: 5640, Loss: 0.6547369956970215\n",
      "i: 5660, Loss: 0.6547277569770813\n",
      "i: 5680, Loss: 0.6547184586524963\n",
      "i: 5700, Loss: 0.6547124981880188\n",
      "i: 5720, Loss: 0.6547053456306458\n",
      "i: 5740, Loss: 0.6546933054924011\n",
      "i: 5760, Loss: 0.6546866297721863\n",
      "i: 5780, Loss: 0.6546768546104431\n",
      "i: 5800, Loss: 0.6546651124954224\n",
      "i: 5820, Loss: 0.6546580195426941\n",
      "i: 5840, Loss: 0.6546505093574524\n",
      "i: 5860, Loss: 0.6546422243118286\n",
      "i: 5880, Loss: 0.6546332836151123\n",
      "i: 5900, Loss: 0.6546247005462646\n",
      "i: 5920, Loss: 0.6546182632446289\n",
      "i: 5940, Loss: 0.6546100974082947\n",
      "i: 5960, Loss: 0.6546018719673157\n",
      "i: 5980, Loss: 0.6545941829681396\n",
      "i: 6000, Loss: 0.6545877456665039\n",
      "i: 6020, Loss: 0.6545829772949219\n",
      "i: 6040, Loss: 0.6545724868774414\n",
      "i: 6060, Loss: 0.6545675992965698\n",
      "i: 6080, Loss: 0.6545606255531311\n",
      "i: 6100, Loss: 0.6545522212982178\n",
      "i: 6120, Loss: 0.6545460820198059\n",
      "i: 6140, Loss: 0.6545400023460388\n",
      "i: 6160, Loss: 0.6545347571372986\n",
      "i: 6180, Loss: 0.6545290350914001\n",
      "i: 6200, Loss: 0.6545219421386719\n",
      "i: 6220, Loss: 0.6545138359069824\n",
      "i: 6240, Loss: 0.6545088887214661\n",
      "i: 6260, Loss: 0.6545063257217407\n",
      "i: 6280, Loss: 0.6545007824897766\n",
      "i: 6300, Loss: 0.6544930338859558\n",
      "i: 6320, Loss: 0.6544862985610962\n",
      "i: 6340, Loss: 0.6544793844223022\n",
      "i: 6360, Loss: 0.6544687151908875\n",
      "i: 6380, Loss: 0.6544603109359741\n",
      "i: 6400, Loss: 0.6544507145881653\n",
      "i: 6420, Loss: 0.6544421315193176\n",
      "i: 6440, Loss: 0.6544355750083923\n",
      "i: 6460, Loss: 0.6544296741485596\n",
      "i: 6480, Loss: 0.6544188261032104\n",
      "i: 6500, Loss: 0.6544111371040344\n",
      "i: 6520, Loss: 0.6544041037559509\n",
      "i: 6540, Loss: 0.6543964147567749\n",
      "i: 6560, Loss: 0.6543881297111511\n",
      "i: 6580, Loss: 0.6543787121772766\n",
      "i: 6600, Loss: 0.6543728113174438\n",
      "i: 6620, Loss: 0.6543661952018738\n",
      "i: 6640, Loss: 0.6543580889701843\n",
      "i: 6660, Loss: 0.6543515920639038\n",
      "i: 6680, Loss: 0.6543446183204651\n",
      "i: 6700, Loss: 0.6543377041816711\n",
      "i: 6720, Loss: 0.6543335318565369\n",
      "i: 6740, Loss: 0.6543259620666504\n",
      "i: 6760, Loss: 0.654320478439331\n",
      "i: 6780, Loss: 0.6543110013008118\n",
      "i: 6800, Loss: 0.654303252696991\n",
      "i: 6820, Loss: 0.6542962193489075\n",
      "i: 6840, Loss: 0.6542916893959045\n",
      "i: 6860, Loss: 0.6542854905128479\n",
      "i: 6880, Loss: 0.6542790532112122\n",
      "i: 6900, Loss: 0.6542701125144958\n",
      "i: 6920, Loss: 0.6542637348175049\n",
      "i: 6940, Loss: 0.6542552709579468\n",
      "i: 6960, Loss: 0.6542482376098633\n",
      "i: 6980, Loss: 0.6542386412620544\n",
      "i: 7000, Loss: 0.6542357802391052\n",
      "i: 7020, Loss: 0.6542283296585083\n",
      "i: 7040, Loss: 0.6542220711708069\n",
      "i: 7060, Loss: 0.6542151570320129\n",
      "i: 7080, Loss: 0.654208779335022\n",
      "i: 7100, Loss: 0.6542019248008728\n",
      "i: 7120, Loss: 0.6541959643363953\n",
      "i: 7140, Loss: 0.6541891098022461\n",
      "i: 7160, Loss: 0.6541849374771118\n",
      "i: 7180, Loss: 0.6541789174079895\n",
      "i: 7200, Loss: 0.6541714072227478\n",
      "i: 7220, Loss: 0.6541657447814941\n",
      "i: 7240, Loss: 0.6541590690612793\n",
      "i: 7260, Loss: 0.654148519039154\n",
      "i: 7280, Loss: 0.6541455984115601\n",
      "i: 7300, Loss: 0.6541394591331482\n",
      "i: 7320, Loss: 0.6541353464126587\n",
      "i: 7340, Loss: 0.6541308164596558\n",
      "i: 7360, Loss: 0.6541274189949036\n",
      "i: 7380, Loss: 0.6541227698326111\n",
      "i: 7400, Loss: 0.6541170477867126\n",
      "i: 7420, Loss: 0.6541106700897217\n",
      "i: 7440, Loss: 0.6541049480438232\n",
      "i: 7460, Loss: 0.6540964245796204\n",
      "i: 7480, Loss: 0.6540902853012085\n",
      "i: 7500, Loss: 0.6540840268135071\n",
      "i: 7520, Loss: 0.654079794883728\n",
      "i: 7540, Loss: 0.6540728211402893\n",
      "i: 7560, Loss: 0.6540687084197998\n",
      "i: 7580, Loss: 0.6540632247924805\n",
      "i: 7600, Loss: 0.6540601253509521\n",
      "i: 7620, Loss: 0.6540530323982239\n",
      "i: 7640, Loss: 0.6540476083755493\n",
      "i: 7660, Loss: 0.6540421843528748\n",
      "i: 7680, Loss: 0.6540341973304749\n",
      "i: 7700, Loss: 0.6540277004241943\n",
      "i: 7720, Loss: 0.6540223360061646\n",
      "i: 7740, Loss: 0.6540173888206482\n",
      "i: 7760, Loss: 0.6540086269378662\n",
      "i: 7780, Loss: 0.6540027260780334\n",
      "i: 7800, Loss: 0.6539967656135559\n",
      "i: 7820, Loss: 0.6539919376373291\n",
      "i: 7840, Loss: 0.6539825797080994\n",
      "i: 7860, Loss: 0.6539763808250427\n",
      "i: 7880, Loss: 0.6539736390113831\n",
      "i: 7900, Loss: 0.6539689302444458\n",
      "i: 7920, Loss: 0.6539605259895325\n",
      "i: 7940, Loss: 0.653952956199646\n",
      "i: 7960, Loss: 0.6539447903633118\n",
      "i: 7980, Loss: 0.6539396047592163\n",
      "i: 8000, Loss: 0.6539325714111328\n",
      "i: 8020, Loss: 0.6539275050163269\n",
      "i: 8040, Loss: 0.6539209485054016\n",
      "i: 8060, Loss: 0.6539146304130554\n",
      "i: 8080, Loss: 0.6539076566696167\n",
      "i: 8100, Loss: 0.653899610042572\n",
      "i: 8120, Loss: 0.6538891196250916\n",
      "i: 8140, Loss: 0.6538816094398499\n",
      "i: 8160, Loss: 0.6538781523704529\n",
      "i: 8180, Loss: 0.6538732051849365\n",
      "i: 8200, Loss: 0.6538682579994202\n",
      "i: 8220, Loss: 0.6538606286048889\n",
      "i: 8240, Loss: 0.6538533568382263\n",
      "i: 8260, Loss: 0.6538462042808533\n",
      "i: 8280, Loss: 0.6538394093513489\n",
      "i: 8300, Loss: 0.6538337469100952\n",
      "i: 8320, Loss: 0.6538287401199341\n",
      "i: 8340, Loss: 0.6538242101669312\n",
      "i: 8360, Loss: 0.6538168787956238\n",
      "i: 8380, Loss: 0.6538114547729492\n",
      "i: 8400, Loss: 0.653806209564209\n",
      "i: 8420, Loss: 0.6538000106811523\n",
      "i: 8440, Loss: 0.6537902355194092\n",
      "i: 8460, Loss: 0.6537840962409973\n",
      "i: 8480, Loss: 0.6537768244743347\n",
      "i: 8500, Loss: 0.653771698474884\n",
      "i: 8520, Loss: 0.6537660956382751\n",
      "i: 8540, Loss: 0.6537614464759827\n",
      "i: 8560, Loss: 0.6537531614303589\n",
      "i: 8580, Loss: 0.6537452340126038\n",
      "i: 8600, Loss: 0.653738260269165\n",
      "i: 8620, Loss: 0.6537328362464905\n",
      "i: 8640, Loss: 0.6537256836891174\n",
      "i: 8660, Loss: 0.653720498085022\n",
      "i: 8680, Loss: 0.6537119150161743\n",
      "i: 8700, Loss: 0.6537043452262878\n",
      "i: 8720, Loss: 0.6536988615989685\n",
      "i: 8740, Loss: 0.653691291809082\n",
      "i: 8760, Loss: 0.653684139251709\n",
      "i: 8780, Loss: 0.6536788940429688\n",
      "i: 8800, Loss: 0.6536715626716614\n",
      "i: 8820, Loss: 0.6536665558815002\n",
      "i: 8840, Loss: 0.6536604166030884\n",
      "i: 8860, Loss: 0.6536558866500854\n",
      "i: 8880, Loss: 0.6536492705345154\n",
      "i: 8900, Loss: 0.6536434888839722\n",
      "i: 8920, Loss: 0.6536362171173096\n",
      "i: 8940, Loss: 0.6536298990249634\n"
     ]
    }
   ],
   "source": [
    "def to_training(s, dr, dh):\n",
    "    l = s.tolist()\n",
    "    l.append(dr)\n",
    "    l.append(dh)\n",
    "    return l\n",
    "\n",
    "def segments_to_training(segments):\n",
    "    x = []\n",
    "    y = []\n",
    "    for (s, dr, dh), action in segments:\n",
    "        l = to_training(s, dr, dh)\n",
    "        x.append(l)\n",
    "        y.append(action)\n",
    "        \n",
    "    x = torch.tensor(x).float().to(device)\n",
    "    y = torch.tensor(y).float().to(device)\n",
    "    \n",
    "    return x, y\n",
    "        \n",
    "# accuracy_m = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    predictions = model(inputs)\n",
    "    \n",
    "    #print(predictions, targets)\n",
    "    \n",
    "    loss = loss_object(predictions, targets.unsqueeze(1))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def generate_episode(cmd):\n",
    "    s = env.reset()\n",
    "    done = False\n",
    "    ep_reward = 0.0\n",
    "    \n",
    "    t = Trajectory()\n",
    "    while not done:\n",
    "        (dh, dr) = cmd\n",
    "        inputs = torch.tensor([to_training(s, dr, dh)]).float().to(device)\n",
    "        \n",
    "        action_probs = model(inputs)\n",
    "        action_probs = F.sigmoid(action_probs) #, dim=-1)\n",
    "        \n",
    "        m = torch.distributions.bernoulli.Bernoulli(probs=action_probs) #categorical.Categorical(probs=action_probs)\n",
    "        action = int(m.sample().squeeze().cpu().numpy())\n",
    "        \n",
    "        # env.render()\n",
    "        s_old = s\n",
    "        \n",
    "        s, reward, done, info = env.step(action)\n",
    "        t.add(s_old, action, reward, s)\n",
    "        \n",
    "        ep_reward += reward\n",
    "        dh = dh - 1\n",
    "        dr = dr - reward\n",
    "        cmd = (dh, dr)\n",
    "    \n",
    "    # print(f'Episode reward: {ep_reward}')\n",
    "    rb.add(t)\n",
    "    return ep_reward\n",
    "    \n",
    "    \n",
    "epochs = 100000\n",
    "\n",
    "for i in range(1, epochs+1):\n",
    "    segments = rb.sample(batch_size)\n",
    "    segments = np.array(segments)\n",
    "    x, y = segments_to_training(segments)\n",
    "    loss = train_step(x, y)\n",
    "    loss_sum += loss\n",
    "    loss_count += 1\n",
    "    \n",
    "    if i % 10000 == 0:\n",
    "        rewards = [] \n",
    "        for e in range(100):\n",
    "            cmd = rb.sample_command()\n",
    "            rewards.append(generate_episode(cmd))\n",
    "        \n",
    "        print(f\"Average Episode Reward: {np.mean(rewards)}\")\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "        print(f'i: {i}, Loss: {loss_sum/loss_count}') #'\\t Accuracy: {accuracy_m.result()}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500.0, 500.0)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb.sample_command()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A1:6 Generate episodes using Alg 2 and add to replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = (500, 500)#rb.sample_command()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Episode Reward: 268.09\n"
     ]
    }
   ],
   "source": [
    "avg_rewards = []\n",
    "\n",
    "def test(cmd):\n",
    "    s = env.reset()\n",
    "    done = False\n",
    "    ep_reward = 0.0\n",
    "    \n",
    "    while not done:\n",
    "        (dh, dr) = cmd\n",
    "        inputs = torch.tensor([to_training(s, dr, dh)]).float().to(device)\n",
    "        \n",
    "        action_probs = model(inputs)\n",
    "        action_probs = F.sigmoid(action_probs) #, dim=-1)\n",
    "        \n",
    "        m = torch.distributions.bernoulli.Bernoulli(probs=action_probs) #torch.distributions.categorical.Categorical(probs=action_probs)\n",
    "        action = int(m.sample().squeeze().cpu().numpy())\n",
    "        \n",
    "        #env.render()\n",
    "        s_old = s\n",
    "        \n",
    "        s, reward, done, info = env.step(action)\n",
    "        \n",
    "        ep_reward += reward\n",
    "        dh = dh - 1\n",
    "        dr = dr - reward\n",
    "        cmd = (dh, dr)\n",
    "    \n",
    "    # print(f'Episode reward: {ep_reward}')\n",
    "    return ep_reward\n",
    "\n",
    "rewards = [] \n",
    "for e in range(100):\n",
    "    rewards.append(test(cmd))\n",
    "\n",
    "# env.close()\n",
    "print(f\"Average Episode Reward: {np.mean(rewards)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

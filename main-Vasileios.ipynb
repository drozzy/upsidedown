{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trajectory(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.trajectory = []\n",
    "        self.total_return = 0\n",
    "        self.length = 0\n",
    "        \n",
    "    def add(self, state, action, reward, state_prime):\n",
    "        self.trajectory.append((state, action, reward, state_prime))\n",
    "        self.total_return += reward\n",
    "        self.length += 1\n",
    "        \n",
    "    def sample_segment(self):\n",
    "        T = len(self.trajectory)\n",
    "\n",
    "        t1 = np.random.randint(1, T+1)\n",
    "        t2 = np.random.randint(t1, T+1)\n",
    "\n",
    "        state = self.trajectory[t1-1][0]\n",
    "        action = self.trajectory[t1-1][1]\n",
    "\n",
    "        d_r = 0.0\n",
    "        for i in range(t1, t2 + 1):\n",
    "            d_r += self.trajectory[i-1][2]\n",
    "\n",
    "        d_h = t2 - t1 + 1.0\n",
    "\n",
    "        return ((state,d_r,d_h),action)\n",
    "    \n",
    "class ReplayBuffer(object):\n",
    "    \n",
    "    def __init__(self, max_size, last_few):\n",
    "        \"\"\"\n",
    "        @param last_few: Number of episodes from the end of the replay buffer\n",
    "        used for sampling exploratory commands.\n",
    "        \"\"\"\n",
    "        self.max_size = max_size\n",
    "        self.cur_size = 0\n",
    "        self.buffer = []\n",
    "        \n",
    "        self.last_few = last_few\n",
    "        \n",
    "    def add(self, trajectory):\n",
    "        self.buffer.append(trajectory)\n",
    "        \n",
    "        self.buffer = sorted(self.buffer, key=lambda x: x.total_return, reverse=True)\n",
    "        self.buffer = self.buffer[:self.max_size]\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        trajectories = np.random.choice(self.buffer, batch_size, replace=True)\n",
    "        \n",
    "        segments = []\n",
    "        \n",
    "        for t in trajectories:\n",
    "            segments.append(t.sample_segment())\n",
    "            \n",
    "        return segments\n",
    "    \n",
    "    def sample_command(self):\n",
    "        eps = self.buffer[:self.last_few]\n",
    "        \n",
    "        dh_0 = np.mean([e.length for e in eps])\n",
    "        \n",
    "        m = np.mean([e.total_return for e in eps])\n",
    "        s = np.std([e.total_return for e in eps])\n",
    "        \n",
    "        dr_0 = np.random.uniform(m, m+s)\n",
    "        \n",
    "        return dh_0, dr_0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1-1. Initialize replay buffer with warm-up episodes using random actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Episode Reward: 22.2368\n"
     ]
    }
   ],
   "source": [
    "rb = ReplayBuffer(5000, 100)\n",
    "\n",
    "avg_rewards = []\n",
    "\n",
    "for _ in range(5000):\n",
    "    s = env.reset()\n",
    "    done = False\n",
    "    ep_reward = 0.0\n",
    "    t = Trajectory()\n",
    "    while not done:\n",
    "        # env.render()\n",
    "        s_old = s\n",
    "        action = env.action_space.sample()\n",
    "        s, reward, done, info = env.step(action)\n",
    "        t.add(s_old, action, reward, s)\n",
    "        ep_reward += reward\n",
    "    avg_rewards.append(ep_reward)    \n",
    "    # print(f'Episode reward: {ep_reward}')\n",
    "    rb.add(t)\n",
    "    \n",
    "    \n",
    "env.close()\n",
    "print(f\"Average Episode Reward: {np.mean(avg_rewards)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1-2 Initialize a behavior function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamLR(torch.optim.lr_scheduler._LRScheduler):\n",
    "    \"\"\"\n",
    "    Implements the Noam Learning rate schedule. This corresponds to increasing the learning rate\n",
    "    linearly for the first ``warmup_steps`` training steps, and decreasing it thereafter proportionally\n",
    "    to the inverse square root of the step number, scaled by the inverse square root of the\n",
    "    dimensionality of the model. Time will tell if this is just madness or it's actually important.\n",
    "    Parameters\n",
    "    ----------\n",
    "    warmup_steps: ``int``, required.\n",
    "        The number of steps to linearly increase the learning rate.\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, warmup_steps):\n",
    "        self.warmup_steps = warmup_steps\n",
    "        super().__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        last_epoch = max(1, self.last_epoch)\n",
    "        scale = self.warmup_steps ** 0.5 * min(last_epoch ** (-0.5), last_epoch * self.warmup_steps ** (-1.5))\n",
    "        return [base_lr * scale for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Behavior(nn.Module):\n",
    "    def __init__(self, input_shape, num_actions):\n",
    "        super(Behavior, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape,512)\n",
    "        self.fc2 = nn.Linear(512,512)\n",
    "        self.fc3 = nn.Linear(512,512)\n",
    "        self.fc4 = nn.Linear(512,512)\n",
    "        self.fc5 = nn.Linear(512,num_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = F.relu(self.fc1(x))\n",
    "        output = F.relu(self.fc2(output))\n",
    "        output = F.relu(self.fc3(output))\n",
    "        output = F.relu(self.fc4(output))\n",
    "        output = self.fc5(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "d = env.observation_space.shape[0]\n",
    "model = Behavior(input_shape=d+2, num_actions=1).to(device) # env.action_space.n\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "lr_scheduler = NoamLR(optimizer, 50000)\n",
    "\n",
    "loss_object = torch.nn.BCEWithLogitsLoss().to(device) #CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "### A1-3: while stopping criteria is not reached do:\n",
    "### A1-4:   Improve the behavior function by training on replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_sum = 0\n",
    "loss_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 20, Loss: 0.6966964602470398\n",
      "i: 40, Loss: 0.6962608695030212\n",
      "i: 60, Loss: 0.695766806602478\n",
      "i: 80, Loss: 0.6953386068344116\n",
      "i: 100, Loss: 0.6949957609176636\n",
      "i: 120, Loss: 0.6947757601737976\n",
      "i: 140, Loss: 0.6945681571960449\n",
      "i: 160, Loss: 0.6943745613098145\n",
      "i: 180, Loss: 0.6942179203033447\n",
      "i: 200, Loss: 0.6940911412239075\n",
      "i: 220, Loss: 0.6939490437507629\n",
      "i: 240, Loss: 0.6938275098800659\n",
      "i: 260, Loss: 0.6936827898025513\n",
      "i: 280, Loss: 0.6935606002807617\n",
      "i: 300, Loss: 0.6934188008308411\n",
      "i: 320, Loss: 0.6932811737060547\n",
      "i: 340, Loss: 0.6931300163269043\n",
      "i: 360, Loss: 0.6929775476455688\n",
      "i: 380, Loss: 0.6928224563598633\n",
      "i: 400, Loss: 0.6926590800285339\n",
      "i: 420, Loss: 0.6924958825111389\n",
      "i: 440, Loss: 0.6923493146896362\n",
      "i: 460, Loss: 0.6921654343605042\n",
      "i: 480, Loss: 0.6919947862625122\n",
      "i: 500, Loss: 0.6918227076530457\n",
      "i: 520, Loss: 0.6916201114654541\n",
      "i: 540, Loss: 0.6913687586784363\n",
      "i: 560, Loss: 0.6911411285400391\n",
      "i: 580, Loss: 0.6909313797950745\n",
      "i: 600, Loss: 0.6906948685646057\n",
      "i: 620, Loss: 0.6904379725456238\n",
      "i: 640, Loss: 0.6901921033859253\n",
      "i: 660, Loss: 0.68992680311203\n",
      "i: 680, Loss: 0.6896706819534302\n",
      "i: 700, Loss: 0.6894243359565735\n",
      "i: 720, Loss: 0.689200758934021\n",
      "i: 740, Loss: 0.6889681816101074\n",
      "i: 760, Loss: 0.6887122988700867\n",
      "i: 780, Loss: 0.6884305477142334\n",
      "i: 800, Loss: 0.6881520748138428\n",
      "i: 820, Loss: 0.6879065036773682\n",
      "i: 840, Loss: 0.6876102089881897\n",
      "i: 860, Loss: 0.6873767375946045\n",
      "i: 880, Loss: 0.687153160572052\n",
      "i: 900, Loss: 0.6868771910667419\n",
      "i: 920, Loss: 0.686613142490387\n",
      "i: 940, Loss: 0.6864559650421143\n",
      "i: 960, Loss: 0.6862040162086487\n",
      "i: 980, Loss: 0.6860137581825256\n",
      "i: 1000, Loss: 0.6857932209968567\n",
      "i: 1020, Loss: 0.6856041550636292\n",
      "i: 1040, Loss: 0.6854315400123596\n",
      "i: 1060, Loss: 0.6851660013198853\n",
      "i: 1080, Loss: 0.6849404573440552\n",
      "i: 1100, Loss: 0.6847355961799622\n",
      "i: 1120, Loss: 0.6845300197601318\n",
      "i: 1140, Loss: 0.68434077501297\n",
      "i: 1160, Loss: 0.6841414570808411\n",
      "i: 1180, Loss: 0.6839432716369629\n",
      "i: 1200, Loss: 0.683769941329956\n",
      "i: 1220, Loss: 0.6835933923721313\n",
      "i: 1240, Loss: 0.6834524273872375\n",
      "i: 1260, Loss: 0.6832577586174011\n",
      "i: 1280, Loss: 0.6830503344535828\n",
      "i: 1300, Loss: 0.6828802227973938\n",
      "i: 1320, Loss: 0.6826791167259216\n",
      "i: 1340, Loss: 0.6825188994407654\n",
      "i: 1360, Loss: 0.6824135184288025\n",
      "i: 1380, Loss: 0.6822190284729004\n",
      "i: 1400, Loss: 0.6820816993713379\n",
      "i: 1420, Loss: 0.6819146275520325\n",
      "i: 1440, Loss: 0.681747555732727\n",
      "i: 1460, Loss: 0.681572437286377\n",
      "i: 1480, Loss: 0.6814208030700684\n",
      "i: 1500, Loss: 0.6812765002250671\n",
      "i: 1520, Loss: 0.6811254024505615\n",
      "i: 1540, Loss: 0.6809419393539429\n",
      "i: 1560, Loss: 0.6808428764343262\n",
      "i: 1580, Loss: 0.680708646774292\n",
      "i: 1600, Loss: 0.6805287599563599\n",
      "i: 1620, Loss: 0.6804268956184387\n",
      "i: 1640, Loss: 0.6802746057510376\n",
      "i: 1660, Loss: 0.680126965045929\n",
      "i: 1680, Loss: 0.679952085018158\n",
      "i: 1700, Loss: 0.679840624332428\n",
      "i: 1720, Loss: 0.6796775460243225\n",
      "i: 1740, Loss: 0.6795583367347717\n",
      "i: 1760, Loss: 0.6794186234474182\n",
      "i: 1780, Loss: 0.6792547702789307\n",
      "i: 1800, Loss: 0.6790898442268372\n",
      "i: 1820, Loss: 0.6789532899856567\n",
      "i: 1840, Loss: 0.6788194179534912\n",
      "i: 1860, Loss: 0.678687334060669\n",
      "i: 1880, Loss: 0.6785776615142822\n",
      "i: 1900, Loss: 0.6784490942955017\n",
      "i: 1920, Loss: 0.6783222556114197\n",
      "i: 1940, Loss: 0.6781894564628601\n",
      "i: 1960, Loss: 0.6780728697776794\n",
      "i: 1980, Loss: 0.6779723167419434\n",
      "i: 2000, Loss: 0.6778345108032227\n",
      "i: 2020, Loss: 0.6776939630508423\n",
      "i: 2040, Loss: 0.677563488483429\n",
      "i: 2060, Loss: 0.6774720549583435\n",
      "i: 2080, Loss: 0.677389919757843\n",
      "i: 2100, Loss: 0.6772583723068237\n",
      "i: 2120, Loss: 0.67717444896698\n",
      "i: 2140, Loss: 0.6770637035369873\n",
      "i: 2160, Loss: 0.676974892616272\n",
      "i: 2180, Loss: 0.6768803596496582\n",
      "i: 2200, Loss: 0.6767735481262207\n",
      "i: 2220, Loss: 0.6766638159751892\n",
      "i: 2240, Loss: 0.6765643954277039\n",
      "i: 2260, Loss: 0.676435649394989\n",
      "i: 2280, Loss: 0.6763135194778442\n",
      "i: 2300, Loss: 0.6762334108352661\n",
      "i: 2320, Loss: 0.6761460900306702\n",
      "i: 2340, Loss: 0.6760961413383484\n",
      "i: 2360, Loss: 0.6760023236274719\n",
      "i: 2380, Loss: 0.6759252548217773\n",
      "i: 2400, Loss: 0.6758436560630798\n",
      "i: 2420, Loss: 0.6757565140724182\n",
      "i: 2440, Loss: 0.6756686568260193\n",
      "i: 2460, Loss: 0.6755445599555969\n",
      "i: 2480, Loss: 0.6754345297813416\n",
      "i: 2500, Loss: 0.675334095954895\n",
      "i: 2520, Loss: 0.6752375364303589\n",
      "i: 2540, Loss: 0.6751487255096436\n",
      "i: 2560, Loss: 0.6750449538230896\n",
      "i: 2580, Loss: 0.6749475002288818\n",
      "i: 2600, Loss: 0.674849271774292\n",
      "i: 2620, Loss: 0.6747539043426514\n",
      "i: 2640, Loss: 0.6746339201927185\n",
      "i: 2660, Loss: 0.6745430827140808\n",
      "i: 2680, Loss: 0.6744670867919922\n",
      "i: 2700, Loss: 0.6743433475494385\n",
      "i: 2720, Loss: 0.6742532253265381\n",
      "i: 2740, Loss: 0.6741770505905151\n",
      "i: 2760, Loss: 0.6740990281105042\n",
      "i: 2780, Loss: 0.6740071177482605\n",
      "i: 2800, Loss: 0.6739050149917603\n",
      "i: 2820, Loss: 0.6738132238388062\n",
      "i: 2840, Loss: 0.6737504005432129\n",
      "i: 2860, Loss: 0.6736533045768738\n",
      "i: 2880, Loss: 0.6735529899597168\n",
      "i: 2900, Loss: 0.6734750866889954\n",
      "i: 2920, Loss: 0.6734099388122559\n",
      "i: 2940, Loss: 0.6733547449111938\n",
      "i: 2960, Loss: 0.6732925176620483\n",
      "i: 2980, Loss: 0.6732150912284851\n",
      "i: 3000, Loss: 0.673139214515686\n",
      "i: 3020, Loss: 0.6730645298957825\n",
      "i: 3040, Loss: 0.672976016998291\n",
      "i: 3060, Loss: 0.672890305519104\n",
      "i: 3080, Loss: 0.6728265881538391\n",
      "i: 3100, Loss: 0.6727579236030579\n",
      "i: 3120, Loss: 0.6726678609848022\n",
      "i: 3140, Loss: 0.6725808382034302\n",
      "i: 3160, Loss: 0.672500491142273\n",
      "i: 3180, Loss: 0.6724385023117065\n",
      "i: 3200, Loss: 0.6723661422729492\n",
      "i: 3220, Loss: 0.6722902655601501\n",
      "i: 3240, Loss: 0.672224223613739\n",
      "i: 3260, Loss: 0.6721497178077698\n",
      "i: 3280, Loss: 0.6720855236053467\n",
      "i: 3300, Loss: 0.6720190644264221\n",
      "i: 3320, Loss: 0.6719655394554138\n",
      "i: 3340, Loss: 0.6719087362289429\n",
      "i: 3360, Loss: 0.6718602180480957\n",
      "i: 3380, Loss: 0.6718143224716187\n",
      "i: 3400, Loss: 0.671746015548706\n",
      "i: 3420, Loss: 0.6716771721839905\n",
      "i: 3440, Loss: 0.6716050505638123\n",
      "i: 3460, Loss: 0.6715523600578308\n",
      "i: 3480, Loss: 0.6714863777160645\n",
      "i: 3500, Loss: 0.671407163143158\n",
      "i: 3520, Loss: 0.671359121799469\n",
      "i: 3540, Loss: 0.6713026762008667\n",
      "i: 3560, Loss: 0.6712453961372375\n",
      "i: 3580, Loss: 0.6711710095405579\n",
      "i: 3600, Loss: 0.6711029410362244\n",
      "i: 3620, Loss: 0.6710450649261475\n",
      "i: 3640, Loss: 0.6709721684455872\n",
      "i: 3660, Loss: 0.670911431312561\n",
      "i: 3680, Loss: 0.670855700969696\n",
      "i: 3700, Loss: 0.6707946062088013\n",
      "i: 3720, Loss: 0.6707502007484436\n",
      "i: 3740, Loss: 0.6706928014755249\n",
      "i: 3760, Loss: 0.6706322431564331\n",
      "i: 3780, Loss: 0.6705681681632996\n",
      "i: 3800, Loss: 0.6705034375190735\n",
      "i: 3820, Loss: 0.6704440116882324\n",
      "i: 3840, Loss: 0.6703914403915405\n",
      "i: 3860, Loss: 0.6703255772590637\n",
      "i: 3880, Loss: 0.6702964305877686\n",
      "i: 3900, Loss: 0.6702465415000916\n",
      "i: 3920, Loss: 0.6701993942260742\n",
      "i: 3940, Loss: 0.6701510548591614\n",
      "i: 3960, Loss: 0.670123815536499\n",
      "i: 3980, Loss: 0.6700913906097412\n",
      "i: 4000, Loss: 0.6700440645217896\n",
      "i: 4020, Loss: 0.6699827313423157\n",
      "i: 4040, Loss: 0.6699216365814209\n",
      "i: 4060, Loss: 0.6698583960533142\n",
      "i: 4080, Loss: 0.6698090434074402\n",
      "i: 4100, Loss: 0.6697531342506409\n",
      "i: 4120, Loss: 0.6696978807449341\n",
      "i: 4140, Loss: 0.6696524620056152\n",
      "i: 4160, Loss: 0.6696062684059143\n",
      "i: 4180, Loss: 0.6695452928543091\n",
      "i: 4200, Loss: 0.6694942712783813\n",
      "i: 4220, Loss: 0.6694462895393372\n",
      "i: 4240, Loss: 0.669391930103302\n",
      "i: 4260, Loss: 0.6693341732025146\n",
      "i: 4280, Loss: 0.6692689657211304\n",
      "i: 4300, Loss: 0.6692238450050354\n",
      "i: 4320, Loss: 0.6691696643829346\n",
      "i: 4340, Loss: 0.6691399216651917\n",
      "i: 4360, Loss: 0.6690821051597595\n",
      "i: 4380, Loss: 0.6690398454666138\n",
      "i: 4400, Loss: 0.6689797043800354\n",
      "i: 4420, Loss: 0.6689223051071167\n",
      "i: 4440, Loss: 0.6688818335533142\n",
      "i: 4460, Loss: 0.6688335537910461\n",
      "i: 4480, Loss: 0.6688026189804077\n",
      "i: 4500, Loss: 0.6687471270561218\n",
      "i: 4520, Loss: 0.6686999201774597\n",
      "i: 4540, Loss: 0.6686583161354065\n",
      "i: 4560, Loss: 0.6686091423034668\n",
      "i: 4580, Loss: 0.6685774922370911\n",
      "i: 4600, Loss: 0.668526291847229\n",
      "i: 4620, Loss: 0.6684882640838623\n",
      "i: 4640, Loss: 0.6684687733650208\n",
      "i: 4660, Loss: 0.6684293746948242\n",
      "i: 4680, Loss: 0.6683895587921143\n",
      "i: 4700, Loss: 0.6683505177497864\n",
      "i: 4720, Loss: 0.6683123707771301\n",
      "i: 4740, Loss: 0.6682628989219666\n",
      "i: 4760, Loss: 0.6682001352310181\n",
      "i: 4780, Loss: 0.6681535840034485\n",
      "i: 4800, Loss: 0.6681033968925476\n",
      "i: 4820, Loss: 0.6680532693862915\n",
      "i: 4840, Loss: 0.6680009961128235\n",
      "i: 4860, Loss: 0.6679510474205017\n",
      "i: 4880, Loss: 0.6679096221923828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 4900, Loss: 0.6678755879402161\n",
      "i: 4920, Loss: 0.667838454246521\n",
      "i: 4940, Loss: 0.6677879095077515\n",
      "i: 4960, Loss: 0.6677395701408386\n",
      "i: 4980, Loss: 0.6676943302154541\n",
      "i: 5000, Loss: 0.6676409840583801\n",
      "i: 5020, Loss: 0.6675950288772583\n",
      "i: 5040, Loss: 0.6675431728363037\n",
      "i: 5060, Loss: 0.667497992515564\n",
      "i: 5080, Loss: 0.6674628257751465\n",
      "i: 5100, Loss: 0.667426347732544\n",
      "i: 5120, Loss: 0.6673836708068848\n",
      "i: 5140, Loss: 0.6673491597175598\n",
      "i: 5160, Loss: 0.6673089265823364\n",
      "i: 5180, Loss: 0.6672724485397339\n",
      "i: 5200, Loss: 0.6672255992889404\n",
      "i: 5220, Loss: 0.667184054851532\n",
      "i: 5240, Loss: 0.6671608686447144\n",
      "i: 5260, Loss: 0.6671088933944702\n",
      "i: 5280, Loss: 0.6670717000961304\n",
      "i: 5300, Loss: 0.667034387588501\n",
      "i: 5320, Loss: 0.6669964790344238\n",
      "i: 5340, Loss: 0.6669535040855408\n",
      "i: 5360, Loss: 0.6669206619262695\n",
      "i: 5380, Loss: 0.6668850779533386\n",
      "i: 5400, Loss: 0.6668460369110107\n",
      "i: 5420, Loss: 0.6668053865432739\n",
      "i: 5440, Loss: 0.6667670607566833\n",
      "i: 5460, Loss: 0.6667313575744629\n",
      "i: 5480, Loss: 0.6666984558105469\n",
      "i: 5500, Loss: 0.6666581034660339\n",
      "i: 5520, Loss: 0.6666163802146912\n",
      "i: 5540, Loss: 0.6665765643119812\n",
      "i: 5560, Loss: 0.6665483713150024\n",
      "i: 5580, Loss: 0.6665151119232178\n",
      "i: 5600, Loss: 0.6665067076683044\n",
      "i: 5620, Loss: 0.6664861440658569\n",
      "i: 5640, Loss: 0.6664601564407349\n",
      "i: 5660, Loss: 0.666441023349762\n",
      "i: 5680, Loss: 0.6664058566093445\n",
      "i: 5700, Loss: 0.6663618087768555\n",
      "i: 5720, Loss: 0.6663187146186829\n",
      "i: 5740, Loss: 0.6662900447845459\n",
      "i: 5760, Loss: 0.6662552952766418\n",
      "i: 5780, Loss: 0.6662254929542542\n",
      "i: 5800, Loss: 0.6661944389343262\n",
      "i: 5820, Loss: 0.6661711931228638\n",
      "i: 5840, Loss: 0.6661332249641418\n",
      "i: 5860, Loss: 0.6660898923873901\n",
      "i: 5880, Loss: 0.666050374507904\n",
      "i: 5900, Loss: 0.6660211682319641\n",
      "i: 5920, Loss: 0.6660018563270569\n",
      "i: 5940, Loss: 0.6659649610519409\n",
      "i: 5960, Loss: 0.6659340262413025\n",
      "i: 5980, Loss: 0.6659080386161804\n",
      "i: 6000, Loss: 0.6658729314804077\n",
      "i: 6020, Loss: 0.665848970413208\n",
      "i: 6040, Loss: 0.6658135652542114\n",
      "i: 6060, Loss: 0.6657829880714417\n",
      "i: 6080, Loss: 0.6657470464706421\n",
      "i: 6100, Loss: 0.6657151579856873\n",
      "i: 6120, Loss: 0.6656955480575562\n",
      "i: 6140, Loss: 0.6656523942947388\n",
      "i: 6160, Loss: 0.6656129956245422\n",
      "i: 6180, Loss: 0.6655945777893066\n",
      "i: 6200, Loss: 0.6655699014663696\n",
      "i: 6220, Loss: 0.6655372977256775\n",
      "i: 6240, Loss: 0.6655123233795166\n",
      "i: 6260, Loss: 0.6654785871505737\n",
      "i: 6280, Loss: 0.6654493808746338\n",
      "i: 6300, Loss: 0.6654301881790161\n",
      "i: 6320, Loss: 0.6653956174850464\n",
      "i: 6340, Loss: 0.6653604507446289\n",
      "i: 6360, Loss: 0.6653324961662292\n",
      "i: 6380, Loss: 0.6652966141700745\n",
      "i: 6400, Loss: 0.6652623414993286\n",
      "i: 6420, Loss: 0.665219247341156\n",
      "i: 6440, Loss: 0.6651896834373474\n",
      "i: 6460, Loss: 0.6651594638824463\n",
      "i: 6480, Loss: 0.6651203036308289\n",
      "i: 6500, Loss: 0.6650952696800232\n",
      "i: 6520, Loss: 0.665055513381958\n",
      "i: 6540, Loss: 0.6650238633155823\n",
      "i: 6560, Loss: 0.6649929285049438\n",
      "i: 6580, Loss: 0.6649712324142456\n",
      "i: 6600, Loss: 0.6649415493011475\n",
      "i: 6620, Loss: 0.6649149060249329\n",
      "i: 6640, Loss: 0.664887011051178\n",
      "i: 6660, Loss: 0.6648560166358948\n",
      "i: 6680, Loss: 0.6648364067077637\n",
      "i: 6700, Loss: 0.6648008227348328\n",
      "i: 6720, Loss: 0.6647732257843018\n",
      "i: 6740, Loss: 0.6647474765777588\n"
     ]
    }
   ],
   "source": [
    "def to_training(s, dr, dh):\n",
    "    l = s.tolist()\n",
    "    l.append(dr)\n",
    "    l.append(dh)\n",
    "    return l\n",
    "\n",
    "def segments_to_training(segments):\n",
    "    x = []\n",
    "    y = []\n",
    "    for (s, dr, dh), action in segments:\n",
    "        l = to_training(s, dr, dh)\n",
    "        x.append(l)\n",
    "        y.append(action)\n",
    "        \n",
    "    x = torch.tensor(x).float().to(device)\n",
    "    y = torch.tensor(y).float().to(device)\n",
    "    \n",
    "    return x, y\n",
    "        \n",
    "# accuracy_m = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    predictions = model(inputs)\n",
    "    \n",
    "    #print(predictions, targets)\n",
    "    \n",
    "    loss = loss_object(predictions, targets.unsqueeze(1))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def generate_episode(cmd):\n",
    "    s = env.reset()\n",
    "    done = False\n",
    "    ep_reward = 0.0\n",
    "    \n",
    "    t = Trajectory()\n",
    "    while not done:\n",
    "        (dh, dr) = cmd\n",
    "        inputs = torch.tensor([to_training(s, dr, dh)]).float().to(device)\n",
    "        \n",
    "        action_probs = model(inputs)\n",
    "        action_probs = F.sigmoid(action_probs) #, dim=-1)\n",
    "        \n",
    "        m = torch.distributions.bernoulli.Bernoulli(probs=action_probs) #categorical.Categorical(probs=action_probs)\n",
    "        action = int(m.sample().squeeze().cpu().numpy())\n",
    "        \n",
    "        # env.render()\n",
    "        s_old = s\n",
    "        \n",
    "        s, reward, done, info = env.step(action)\n",
    "        t.add(s_old, action, reward, s)\n",
    "        \n",
    "        ep_reward += reward\n",
    "        dh = dh - 1\n",
    "        dr = dr - reward\n",
    "        cmd = (dh, dr)\n",
    "    \n",
    "    # print(f'Episode reward: {ep_reward}')\n",
    "    rb.add(t)\n",
    "    return ep_reward\n",
    "    \n",
    "    \n",
    "epochs = 100000\n",
    "\n",
    "for i in range(1, epochs+1):\n",
    "    segments = rb.sample(batch_size)\n",
    "    segments = np.array(segments)\n",
    "    x, y = segments_to_training(segments)\n",
    "    loss = train_step(x, y)\n",
    "    loss_sum += loss\n",
    "    loss_count += 1\n",
    "    \n",
    "    #if i % 1000 == 0:\n",
    "    lr_scheduler.step()\n",
    "    #print(lr_scheduler.get_lr())\n",
    "    \n",
    "    if i % 10000 == 0:\n",
    "        rewards = [] \n",
    "        for e in range(100):\n",
    "            cmd = rb.sample_command()\n",
    "            rewards.append(generate_episode(cmd))\n",
    "        \n",
    "        print(f\"Average Episode Reward: {np.mean(rewards)}\")\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "        print(f'i: {i}, Loss: {loss_sum/loss_count}') #'\\t Accuracy: {accuracy_m.result()}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.sample_command()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A1:6 Generate episodes using Alg 2 and add to replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = (500, 500)#rb.sample_command()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Episode Reward: 268.09\n"
     ]
    }
   ],
   "source": [
    "avg_rewards = []\n",
    "\n",
    "def test(cmd):\n",
    "    s = env.reset()\n",
    "    done = False\n",
    "    ep_reward = 0.0\n",
    "    \n",
    "    while not done:\n",
    "        (dh, dr) = cmd\n",
    "        inputs = torch.tensor([to_training(s, dr, dh)]).float().to(device)\n",
    "        \n",
    "        action_probs = model(inputs)\n",
    "        action_probs = F.sigmoid(action_probs) #, dim=-1)\n",
    "        \n",
    "        m = torch.distributions.bernoulli.Bernoulli(probs=action_probs) #torch.distributions.categorical.Categorical(probs=action_probs)\n",
    "        action = int(m.sample().squeeze().cpu().numpy())\n",
    "        \n",
    "        #env.render()\n",
    "        s_old = s\n",
    "        \n",
    "        s, reward, done, info = env.step(action)\n",
    "        \n",
    "        ep_reward += reward\n",
    "        dh = dh - 1\n",
    "        dr = dr - reward\n",
    "        cmd = (dh, dr)\n",
    "    \n",
    "    # print(f'Episode reward: {ep_reward}')\n",
    "    return ep_reward\n",
    "\n",
    "rewards = [] \n",
    "for e in range(100):\n",
    "    rewards.append(test(cmd))\n",
    "\n",
    "# env.close()\n",
    "print(f\"Average Episode Reward: {np.mean(rewards)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import gym\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from experiment import rollout, ReplayBuffer, Trajectory, segments_to_training, load_model, save_model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Episode Reward: 21.74\n"
     ]
    }
   ],
   "source": [
    "rb = ReplayBuffer(200, 100)\n",
    "avg_reward = rollout(episodes=1000, env=env, replay_buffer=rb, render=False)\n",
    "\n",
    "print(f\"Average Episode Reward: {avg_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = torch.nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs, targets):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    predictions = model(inputs)\n",
    "    loss = loss_object(predictions, targets.unsqueeze(1))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_sum = 0\n",
    "loss_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 200, Loss: 0.6515129208564758\n",
      "i: 400, Loss: 0.6484588384628296\n",
      "i: 600, Loss: 0.6454616785049438\n",
      "i: 800, Loss: 0.6438441276550293\n",
      "Average Episode Reward: 53.4\n",
      "i: 1000, Loss: 0.6416881084442139\n",
      "i: 1200, Loss: 0.6385904550552368\n",
      "i: 1400, Loss: 0.6354051828384399\n",
      "i: 1600, Loss: 0.6322858333587646\n",
      "i: 1800, Loss: 0.6294998526573181\n",
      "Average Episode Reward: 53.65\n",
      "i: 2000, Loss: 0.6267819404602051\n",
      "i: 2200, Loss: 0.6236968636512756\n",
      "i: 2400, Loss: 0.6204634308815002\n",
      "i: 2600, Loss: 0.6175605654716492\n",
      "i: 2800, Loss: 0.6146635413169861\n",
      "Average Episode Reward: 69.38\n",
      "i: 3000, Loss: 0.6120092272758484\n",
      "i: 3200, Loss: 0.6089345812797546\n",
      "i: 3400, Loss: 0.6058717966079712\n",
      "i: 3600, Loss: 0.6026895046234131\n",
      "i: 3800, Loss: 0.5996562838554382\n",
      "Average Episode Reward: 53.63\n",
      "i: 4000, Loss: 0.5967664122581482\n",
      "i: 4200, Loss: 0.5947983264923096\n",
      "i: 4400, Loss: 0.5925896167755127\n",
      "i: 4600, Loss: 0.5904895663261414\n",
      "i: 4800, Loss: 0.5882615447044373\n",
      "Average Episode Reward: 73.28\n",
      "i: 5000, Loss: 0.5860218405723572\n",
      "i: 5200, Loss: 0.5849398374557495\n",
      "i: 5400, Loss: 0.5835233330726624\n",
      "i: 5600, Loss: 0.582024097442627\n",
      "i: 5800, Loss: 0.5804464221000671\n",
      "Average Episode Reward: 83.59\n",
      "i: 6000, Loss: 0.5787675976753235\n",
      "i: 6200, Loss: 0.5777126550674438\n",
      "i: 6400, Loss: 0.5764349699020386\n",
      "i: 6600, Loss: 0.5750494003295898\n",
      "i: 6800, Loss: 0.5735043287277222\n",
      "Average Episode Reward: 94.95\n",
      "i: 7000, Loss: 0.572002649307251\n",
      "i: 7200, Loss: 0.5710947513580322\n",
      "i: 7400, Loss: 0.5699228644371033\n",
      "i: 7600, Loss: 0.5686031579971313\n",
      "i: 7800, Loss: 0.5672369599342346\n",
      "Average Episode Reward: 88.82\n",
      "i: 8000, Loss: 0.5658413767814636\n",
      "i: 8200, Loss: 0.5652467608451843\n",
      "i: 8400, Loss: 0.5643089413642883\n",
      "i: 8600, Loss: 0.5632858872413635\n",
      "i: 8800, Loss: 0.5621756911277771\n",
      "Average Episode Reward: 97.25\n",
      "i: 9000, Loss: 0.5610221028327942\n",
      "i: 9200, Loss: 0.5605031847953796\n",
      "i: 9400, Loss: 0.5596643686294556\n",
      "i: 9600, Loss: 0.5587364435195923\n",
      "i: 9800, Loss: 0.5577176213264465\n",
      "Average Episode Reward: 96.5\n",
      "i: 10000, Loss: 0.556640625\n",
      "i: 10200, Loss: 0.55619877576828\n",
      "i: 10400, Loss: 0.5554932355880737\n",
      "i: 10600, Loss: 0.5547122955322266\n",
      "i: 10800, Loss: 0.5539203882217407\n",
      "Average Episode Reward: 70.24\n",
      "i: 11000, Loss: 0.552983820438385\n",
      "i: 11200, Loss: 0.5524651408195496\n",
      "i: 11400, Loss: 0.5518205761909485\n",
      "i: 11600, Loss: 0.5510199069976807\n",
      "i: 11800, Loss: 0.5501898527145386\n",
      "Average Episode Reward: 104.9\n",
      "i: 12000, Loss: 0.549342691898346\n",
      "i: 12200, Loss: 0.5488930940628052\n",
      "i: 12400, Loss: 0.5482743978500366\n",
      "i: 12600, Loss: 0.5476028323173523\n",
      "i: 12800, Loss: 0.5469133853912354\n",
      "Average Episode Reward: 18.89\n",
      "i: 13000, Loss: 0.5461404919624329\n",
      "i: 13200, Loss: 0.5453689694404602\n",
      "i: 13400, Loss: 0.5445465445518494\n",
      "i: 13600, Loss: 0.5436968207359314\n",
      "i: 13800, Loss: 0.5428242087364197\n",
      "Average Episode Reward: 108.72\n",
      "i: 14000, Loss: 0.541888415813446\n",
      "i: 14200, Loss: 0.5413738489151001\n",
      "i: 14400, Loss: 0.5407016277313232\n",
      "i: 14600, Loss: 0.5400037169456482\n",
      "i: 14800, Loss: 0.5391976237297058\n",
      "Average Episode Reward: 136.43\n",
      "i: 15000, Loss: 0.5384252071380615\n",
      "i: 15200, Loss: 0.5380736589431763\n",
      "i: 15400, Loss: 0.5375219583511353\n",
      "i: 15600, Loss: 0.5368604063987732\n",
      "i: 15800, Loss: 0.5361732840538025\n",
      "Average Episode Reward: 76.02\n",
      "i: 16000, Loss: 0.535485029220581\n",
      "i: 16200, Loss: 0.5350857377052307\n",
      "i: 16400, Loss: 0.5345099568367004\n",
      "i: 16600, Loss: 0.5339005589485168\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000000\n",
    "epoch, model, optimizer, loss = load_model(env, device, train=True)\n",
    "\n",
    "for i in range(1, epochs+1):\n",
    "    x, y = rb.sample(batch_size, device)    \n",
    "    loss = train_step(x, y)\n",
    "    loss_sum += loss\n",
    "    loss_count += 1\n",
    "    \n",
    "    if i % 1000 == 0:        \n",
    "        mean_reward = rollout(100, env=env, model=model, sample_action=True, replay_buffer=rb, \n",
    "                              device=device)\n",
    "        \n",
    "        print(f\"Average Episode Reward: {mean_reward}\")        \n",
    "        \n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        print(f'i: {i}, Loss: {loss_sum/loss_count}') #'\\t Accuracy: {accuracy_m.result()}')\n",
    "        save_model(i, model, optimizer, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43.06, 43.32223427058613)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb.sample_command()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model at epoch: 400 with loss 0.6158408522605896\n",
      "Average Episode Reward: 35.666666666666664\n"
     ]
    }
   ],
   "source": [
    "cmd = (500, 500) #rb.sample_command()\n",
    "env = gym.make('CartPole-v1')\n",
    "e, model, _, l = load_model(train=False, env=env, device=device)\n",
    "print(f\"Loaded model at epoch: {e} with loss {l}\")\n",
    "mean_reward = rollout(episodes=3, env=env, model=model, sample_action=True, \n",
    "                      cmd=cmd,\n",
    "                      render=True, device=device)\n",
    "\n",
    "\n",
    "print(f\"Average Episode Reward: {mean_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
